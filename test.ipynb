{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from batch_gen import BatchGenerator\r\n",
    "from model import MultiStageModel\r\n",
    "from random import random\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import numpy as np\r\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "vid_list_file = 'C:/github/casual_tcn/cholec80/train.txt'\r\n",
    "mapping_file = 'C:/github/casual_tcn/cholec80/action_mapping.txt'\r\n",
    "feature_dir = 'C:/github/casual_tcn/cholec80/train_dataset/video_feature@2020/'\r\n",
    "gt_dir = 'C:/github/casual_tcn/cholec80/train_dataset/annotation_folder/'\r\n",
    "\r\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "num_stages = 4      # number of SingleStageModel in MultiStageModel.stages\r\n",
    "num_layers = 10     # number of DilatedResidualLayer in SingleStageModel.layers\r\n",
    "num_f_maps = 64     # number of kernels in DilatedResidualLayer and conv1d layer\r\n",
    "features_dim = 2048 # each feature vector contains 2048 floats\r\n",
    "bz = 1              # batch size\r\n",
    "lr = 0.0005         # learning rate\r\n",
    "num_epochs = 50     # training epoches\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "features = np.load(feature_dir + 'video01.npy').T\r\n",
    "input_x = torch.tensor(features, dtype=torch.float).unsqueeze(0)\r\n",
    "input_x = input_x.to(device)\r\n",
    "model = MultiStageModel(num_stages, num_layers, num_f_maps, features_dim, num_classes=6)\r\n",
    "model.to(device)\r\n",
    "predictions = model(input_x, torch.ones(input_x.size(), device=device))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "print(predictions.shape)\r\n",
    "print(predictions[-1].data.shape)\r\n",
    "print(predictions[-1].shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5, 1, 6, 8666])\n",
      "torch.Size([1, 6, 8666])\n",
      "torch.Size([1, 6, 8666])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "something, predicted = torch.max(predictions[-1].data, 1)\r\n",
    "print(predictions[-1].data.shape)\r\n",
    "print(predicted.shape)\r\n",
    "print(predicted)\r\n",
    "predicted = predicted.squeeze()\r\n",
    "print(predicted.shape)\r\n",
    "print(predicted)\r\n",
    "print(predicted[0].item())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 6, 8666])\n",
      "torch.Size([1, 8666])\n",
      "tensor([[0, 0, 4,  ..., 0, 3, 0]], device='cuda:0')\n",
      "torch.Size([8666])\n",
      "tensor([0, 0, 4,  ..., 0, 3, 0], device='cuda:0')\n",
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "file_ptr = open(mapping_file, 'r')\r\n",
    "actions = file_ptr.read().split('\\n')[:-1] # extract each line into array 'actions'\r\n",
    "file_ptr.close()\r\n",
    "actions_dict = dict()\r\n",
    "for a in actions:\r\n",
    "    actions_dict[a.split()[1]] = int(a.split()[0]) # construct a dictionary: operation_name -> index"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "def read_file(path):\r\n",
    "    with open(path, 'r') as f:\r\n",
    "        content = f.read()\r\n",
    "        f.close()\r\n",
    "    return content\r\n",
    "\r\n",
    "gt_dir = \"C:/github/casual_tcn/cholec80/train_dataset/annotation_folder/\"\r\n",
    "recog_path = \"./results/\"\r\n",
    "file_list = \"C:/github/casual_tcn/cholec80/test.txt\"\r\n",
    "\r\n",
    "gt_content = read_file(gt_dir+\"video01.txt\").split('\\n')[0:-1]\r\n",
    "for i in range(len(gt_content)):\r\n",
    "    gt_content[i] = gt_content[i].split('\\t')[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "recog_file = recog_path + \"video06.txt\"\r\n",
    "recog_content = read_file(recog_file).split('\\n')[1].split()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "import os\r\n",
    "train_vid = [1,20]\r\n",
    "test_vid = [21,40]\r\n",
    "train_list_file = \"C:/github/casual_tcn/cholec80/train.txt\"\r\n",
    "test_list_file = \"C:/github/casual_tcn/cholec80/test.txt\"\r\n",
    "\r\n",
    "if os.path.exists(train_list_file):\r\n",
    "    os.remove(train_list_file)\r\n",
    "file_ptr = open(train_list_file, \"w\")\r\n",
    "for i in range(train_vid[0], train_vid[1]+1):\r\n",
    "    file_ptr.write(\"video%02d.mp4\\n\" % (i))\r\n",
    "file_ptr.close()\r\n",
    "\r\n",
    "if os.path.exists(test_list_file):\r\n",
    "    os.remove(test_list_file)\r\n",
    "file_ptr = open(test_list_file, \"w\")\r\n",
    "for i in range(test_vid[0], test_vid[1]+1):\r\n",
    "    file_ptr.write(\"video%02d.mp4\\n\" % (i))\r\n",
    "file_ptr.close()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}